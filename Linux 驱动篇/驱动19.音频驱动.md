# 一、原理介绍
## 1.1 I2S总线接口
和 I2C、 SPI 这些常见的通信协议一样， I2S 总线用于主控制器和音频 CODEC 芯片之间传输音频数据。I2S 接口需要 3 根信号线(如果需要实现收和发，那么就要 4 根信号线，收和发分别使用一根信号线)： 
 
1、SCK： 串行时钟信号，也叫做位时钟(BCLK)，音频数据的每一位数据都对应一个 SCK，立体声都是双声道的，因此 SCK=2×采样率×采样位数。比如采样率为 44.1KHz、 16 位的立体声音频，那么 SCK=2×44100×16=1411200Hz=1.4112MHz。 
 
2、WS： 字段(声道)选择信号，也叫做 LRCK，也叫做帧时钟，用于切换左右声道数据， WS 为“1”表示正在传输左声道的数据， WS 为“0”表示正在传输右声道的数据。 WS 的频率等于采样率，比如采样率为 44.1KHz 的音频， WS=44.1KHz。  

3、SD： 串行数据信号，也就是我们实际的音频数据，如果要同时实现放音和录音，那么就需  
要 2 根数据线，比如 WM8960 的 ADCDAT 和 DACDAT，就是分别用于录音和放音。不管音频  
数据是多少位的，数据的最高位都是最先传输的。数据的最高位总是出现在一帧开始后(LRCK  
变化)的第 2 个 SCK 脉冲处。  

另外，有时候为了使音频 CODEC 芯片与主控制器之间能够更好的同步，会引入另外一个  
叫做 MCLK 的信号，也叫做主时钟或系统时钟，一般是采样率的 256 倍或 384 倍。

# 二、音频驱动使能
1、需要一个 `WM8960`驱动文件，`IIC`框架的，用来配置 `WM8960` 的功能；

2、需要一个`SOC`端`SAI`外设的驱动文件；

3、需要一个驱动文件，将`WM8960`和`I.MX6ULL`联系起来。

## 2.1 ALSA音频驱动框架
`ASoc`是在 `ALSA` 基础上，针对 `SOC` 另外改进的 `ALSA` 音频驱动框架。目前 ARM 处理的音频驱动框架都是 `ASoC`，分为三部分：`SOC(platform)`、`Codec` 部分、板载硬件`(Machine)`。

1、SOC:具体的SOC音频接口驱动，比如6ULL的SAI接口，都是半导体厂商编写好的；

2、Codec:具体的音频芯片，比如WM8960，IIC驱动。也不需要我们编写，Codec 芯片厂商会写好；

3、板载硬件:Machine部分，将具体的SOC与具体的Codec结合。与具体的硬件设备相关也就是我们要处理的部分。使用 ASOC驱动框架将 SOC与Codec结合。

内核：Docurhentation\sound\alsa\soce

## 2.2 ALSA开发版
1、Codec 部分驱动文件就是` wm8960.c`，IIC接口的；

2、SOC(platform)部分就是`I.MX6ULL`的 SAI驱动，驱动文件就是`fslsai.c`；

3、板载硬件(Machine)部分，sound 节点。驱动文件就是`imx-wm8960.c`。

# 3 ALSA开发版

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0NDM5NjE1MDAsLTU2MTI3NzY5OCwxNz
MyNDA2MzM1LDEyNDExNTk2NzQsLTEyNTU2NDg1Ml19
-->